{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Reinforcement Learning\n",
    "## Project 4: Implement a Basic Driving Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "### Train a Smartcab to Drive\n",
    "A smartcab is a self-driving car from the not-so-distant future that ferries people from one arbitrary location to another. In this project, you will use reinforcement learning to train a smartcab how to drive.\n",
    "### Environment\n",
    "Your smartcab operates in an idealized grid-like city, with roads going North-South and East-West. Other vehicles may be present on the roads, but no pedestrians. There is a traffic light at each intersection that can be in one of two states: North-South open or East-West open.\n",
    "US right-of-way rules apply: On a green light, you can turn left only if there is no oncoming traffic at the intersection coming straight. On a red light, you can turn right if there is no oncoming traffic turning left or traffic from the left going straight.\n",
    "To understand how to correctly yield to oncoming traffic when turning left, you may refer to this [official drivers’ education video](https://www.youtube.com/watch?v=TW0Eq2Q-9Ac), or this [passionate exposition](https://www.youtube.com/watch?v=0EdkxI6NeuA).\n",
    "### Inputs\n",
    "Assume that a higher-level planner assigns a route to the smartcab, splitting it into waypoints at each intersection. And time in this world is quantized. At any instant, the smartcab is at some intersection. Therefore, the next waypoint is always either one block straight ahead, one block left, one block right, one block back or exactly there (reached the destination).\n",
    "The smartcab only has an egocentric view of the intersection it is currently at (sorry, no accurate GPS, no global location). It is able to sense whether the traffic light is green for its direction of movement (heading), and whether there is a car at the intersection on each of the incoming roadways (and which direction they are trying to go).\n",
    "In addition to this, each trip has an associated timer that counts down every time step. If the timer is at 0 and the destination has not been reached, the trip is over, and a new one may start.\n",
    "### Outputs\n",
    "At any instant, the smartcab can either stay put at the current intersection, move one block forward, one block left, or one block right (no backward movement).\n",
    "### Rewards\n",
    "The smartcab gets a reward for each successfully completed trip. A trip is considered “successfully completed” if the passenger is dropped off at the desired destination (some intersection) within a pre-specified time bound (computed with a route plan).\n",
    "It also gets a smaller reward for each correct move executed at an intersection. It gets a small penalty for an incorrect move, and a larger penalty for violating traffic rules and/or causing an accident.\n",
    "### Goal\n",
    "Design the AI driving agent for the smartcab. It should receive the above-mentioned inputs at each time step t, and generate an output move. Based on the rewards and penalties it gets, the agent should learn an optimal policy for driving on city roads, obeying traffic rules correctly, and trying to reach the destination within a goal time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "You need Python 2.7 and [pygame](http://pygame.org/hifi.html) for this project: https://www.pygame.org/wiki/GettingStarted\n",
    "For help with installation, it is best to reach out to the pygame community [[help page](http://www.pygame.org/wiki/info), [Google group](https://groups.google.com/forum/#!forum/pygame-mirror-on-google-groups), [reddit](https://www.reddit.com/r/pygame/)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download\n",
    "Download [smartcab.zip](https://s3.amazonaws.com/content.udacity-data.com/courses/nd009/projects/smartcab.zip), unzip and open the template Python file `agent.py` (do not modify any other file). Perform the following tasks to build your agent, referring to instructions mentioned in `README.md` as well as inline comments in `agent.py`.\n",
    "Also create a project report (e.g. Word or Google doc), and start addressing the questions indicated in italics below. When you have finished the project, save/download the report as a PDF and turn it in with your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a basic driving agent\n",
    "Implement the basic driving agent, which processes the following inputs at each time step:\n",
    "Next waypoint location, relative to its current location and heading,\n",
    "Intersection state (traffic light and presence of cars), and,\n",
    "Current deadline value (time steps remaining),\n",
    "And produces some random move/action `(None, 'forward', 'left', 'right')`. Don’t try to implement the correct strategy! That’s exactly what your agent is supposed to learn.\n",
    "Run this agent within the simulation environment with `enforce_deadline` set to `False` (see `run` function in `agent.py`), and observe how it performs. In this mode, the agent is given unlimited time to reach the destination. The current state, action taken by your agent and reward/penalty earned are shown in the simulator.\n",
    "#### Question 1\n",
    "In your report, mention what you see in the agent’s behavior. Does it eventually make it to the target location?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<br>\n",
    "When letting the agent randomly choosing an action, the agent does not seem to move toward the destination. It walked\n",
    "randomly on the grid. The program was run several times. For trial 1, the agent reached the destination after 53 time\n",
    "steps. For trial 2, the agent reached the destination after 120 time steps. For trial 3, the agent reached the\n",
    "destination after 125 time steps. For trial 4, the agent still had not reached the destination after 200 time steps and the program was terminated. Overall, the agent either did not reach the destination or moved more steps than necessary to reach the destination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and update state\n",
    "Identify a set of states that you think are appropriate for modeling the driving agent. The main source of state variables are current inputs, but not all of them may be worth representing. Also, you can choose to explicitly define states, or use some combination (vector) of inputs as an implicit state.\n",
    "At each time step, process the inputs and update the current state. Run it again (and as often as you need) to observe how the reported state changes through the run.\n",
    "#### Question 2\n",
    "Justify why you picked these set of states, and how they model the agent and its environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<br>\n",
    "The available environment variables are: `deadline (number of timesteps remaining), traffic light (Green, Red), oncoming car (forward, right, left, None), left-coming car (forward, right, left, None), right-coming car (forward, right, left, None), next waypoint (forward, right, left, None)`.\n",
    "A state is defined as a tuple of `(light, oncoming, left, next_waypoint)`. According to the US right-of-way rule, \"On a green light, you can turn left only if there is no oncoming traffic at the intersection coming straight. On a red light, you can turn right if there is no oncoming traffic turning left or traffic from the left going straight.\" Therefore, the agent does not need to care about the actions of the right-coming car. The information on traffic light, oncoming car and left-coming car is sufficient in describing the agent's egocentric view of the current environment on which the agent can choose actions to avoid breaking the traffic rules. Next waypoint tells the direction heading to the destination hence facilitates the agent to make better decisions on choosing the next direction. The agent is expected to learn the optimal policy within a certain deadline which is considered in implementing Q-Learning with a discount rate and a decreasing leraning rate. Hence the count down to deadline is not recorded in the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Q-Learning\n",
    "Implement the Q-Learning algorithm by initializing and updating a table/mapping of Q-values at each time step. Now, instead of randomly selecting an action, pick the best action available from the current state based on Q-values, and return that.\n",
    "Each action generates a corresponding numeric reward or penalty (which may be zero). Your agent should take this into account when updating Q-values. Run it again, and observe the behavior.\n",
    "#### Question 3\n",
    "What changes do you notice in the agent’s behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<br>\n",
    "The agent acts like it is aware of the surrounding environment and breaks less traffic rules. It is also aware of its location relative to the destination and moves toward the destination in fewer actions. However in approximately half of the trials, the agent still cannot reach the destination within the deadline. The agent also tends to run in circle without breaking traffic rules to gain more positive rewards. To enhance the performance, the discount rate and leraning rate need to be further tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhance the driving agent\n",
    "Apply the reinforcement learning techniques you have learnt, and tweak the parameters (e.g. learning rate, discount factor, action selection method, etc.), to improve the performance of your agent. Your goal is to get it to a point so that within 100 trials, the agent is able to learn a feasible policy - i.e. reach the destination within the allotted time, with net reward remaining positive.\n",
    "\n",
    "The formulas for updating Q-values can be found in [this](https://www.udacity.com/course/viewer#!/c-ud728-nd/l-5446820041/m-634899057) video.\n",
    "#### Question 4a\n",
    "Report what changes you made to your basic implementation of Q-Learning to achieve the final version of the agent. How well does it perform?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<br>\n",
    "In the `def chooseAction` function, the best actions with highest Q values are found and listed. To enhance the agent's performance, `next_waypoint` is set to be chosen if it is among one of the best actions.<br>\n",
    "Learning rate alpha and exploration probability epsilon are defiend as `1/t` which approaches to 0 as learning proceeds. Discount rate gamma are tuned with three different values: 0.9, 0.5 and 0.2. Both gamma=0.9 and gamma=0.5 have 1 trial failed while gamma=0.2 succeeds with all trials. Hence optimal gamma is chosen as 0.2.<br>\n",
    "With alpha=1/t, gamma=0.2, epsilon=1/t, the agent reaches the destination within allotted time, with net reward remaining positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1 = 0.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Reward</th>\n",
       "      <th>Reach Destination</th>\n",
       "      <th>Steps Taken</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Net Reward Reach Destination  Steps Taken  Trial\n",
       "0          +                 F           41      0\n",
       "1          +                 T           13      1\n",
       "2          +                 T           13      2\n",
       "3          +                 T           36      3\n",
       "4          +                 T            8      4\n",
       "5          +                 T            7      5\n",
       "6          +                 T           13      6\n",
       "7          +                 T           20      7\n",
       "8          +                 T           14      8\n",
       "9          +                 T           16      9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gamma2 = 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Reward</th>\n",
       "      <th>Reach Destination</th>\n",
       "      <th>Steps Taken</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+</td>\n",
       "      <td>F</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Net Reward Reach Destination  Steps Taken  Trial\n",
       "0          +                 T           12      0\n",
       "1          +                 T           14      1\n",
       "2          +                 T           10      2\n",
       "3          +                 T           14      3\n",
       "4          +                 T            6      4\n",
       "5          +                 T            7      5\n",
       "6          +                 F           31      6\n",
       "7          +                 T            8      7\n",
       "8          +                 T            8      8\n",
       "9          +                 T            6      9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gamma3 = 0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Reward</th>\n",
       "      <th>Reach Destination</th>\n",
       "      <th>Steps Taken</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Net Reward Reach Destination  Steps Taken  Trial\n",
       "0          +                 T           17      0\n",
       "1          +                 T           10      1\n",
       "2          +                 T           17      2\n",
       "3          +                 T            8      3\n",
       "4          +                 T           20      4\n",
       "5          +                 T           18      5\n",
       "6          +                 T            8      6\n",
       "7          +                 T           29      7\n",
       "8          +                 T           13      8\n",
       "9          +                 T           26      9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# learn with gamma = 0.9\n",
    "gamma1 = pd.DataFrame({'Trial': np.array(range(10)),\n",
    "                       'Reach Destination': np.array(list('F' + 'T' * 9)),\n",
    "                       'Steps Taken': np.array([41, 13, 13, 36, 8, 7, 13, 20, 14, 16]),\n",
    "                       'Net Reward': np.array(list('+' * 10))\n",
    "                      })\n",
    "\n",
    "# learn with gamma = 0.5\n",
    "gamma2 = pd.DataFrame({'Trial': np.array(range(10)),\n",
    "                       'Reach Destination': np.array(list('T' * 6 + 'F' + 'T' * 3)),\n",
    "                       'Steps Taken': np.array([12, 14, 10, 14, 6, 7, 31, 8, 8, 6]),\n",
    "                       'Net Reward': np.array(list('+' * 10))\n",
    "                      })\n",
    "# learn with gamma = 0.2\n",
    "gamma3 = pd.DataFrame({'Trial': np.array(range(10)),\n",
    "                       'Reach Destination': np.array(list('T' * 10)),\n",
    "                       'Steps Taken': np.array([17, 10, 17,8, 20, 18, 8, 29, 13, 26]),\n",
    "                       'Net Reward': np.array(list('+' * 10))\n",
    "                      })\n",
    "print 'gamma1 = 0.9'\n",
    "display(gamma1)\n",
    "print \n",
    "print 'gamma2 = 0.5'\n",
    "display(gamma2)\n",
    "print \n",
    "print 'gamma3 = 0.2'\n",
    "display(gamma3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4b\n",
    "Does your agent get close to finding an optimal policy, i.e. reach the destination in the minimum possible time, and not incur any penalties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**<br>\n",
    "Run 30 trials, the average steps for the agent to get to the destination is 13.06; the average net penalty is -2.03.<br>\n",
    "The agent tends to take best actions whenever possiple, therefore sometimes breaking traffic rules but always avoiding taking less optimal actions and running in circle. The agent can always make to the destination within alloted time but with an average penalty of -2.03. One possible explanation might be the absolute value of a reward given to the agent when it's approaching the destination is always greater than the absolute value of a penalty given to the agent when it breaks a traffic rule. Therefore, the agent always prioritize moving toward the destination rather than moving without breaking traffic rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps and Net Penalty for 30 trials:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Penalty</th>\n",
       "      <th>Steps Taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.033333</td>\n",
       "      <td>13.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.066200</td>\n",
       "      <td>5.988111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Net Penalty  Steps Taken\n",
       "count    30.000000    30.000000\n",
       "mean     -2.033333    13.066667\n",
       "std       1.066200     5.988111\n",
       "min      -4.000000     4.000000\n",
       "25%      -3.000000    10.000000\n",
       "50%      -2.000000    12.000000\n",
       "75%      -1.000000    16.000000\n",
       "max       0.000000    29.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Trials:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Penalty</th>\n",
       "      <th>Net Reward</th>\n",
       "      <th>Reach Destination</th>\n",
       "      <th>Steps Taken</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-3</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-3</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-3</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-4</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-2</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-3</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-4</td>\n",
       "      <td>+</td>\n",
       "      <td>T</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Net Penalty Net Reward Reach Destination  Steps Taken  Trial\n",
       "0            -2          +                 T           11      0\n",
       "1            -3          +                 T           19      1\n",
       "2            -2          +                 T           11      2\n",
       "3            -2          +                 T            9      3\n",
       "4            -1          +                 T            6      4\n",
       "5            -2          +                 T           11      5\n",
       "6            -1          +                 T           19      6\n",
       "7            -2          +                 T           12      7\n",
       "8            -2          +                 T           13      8\n",
       "9            -4          +                 T           18      9\n",
       "10           -2          +                 T           16     10\n",
       "11            0          +                 T            4     11\n",
       "12           -2          +                 T            6     12\n",
       "13           -1          +                 T           14     13\n",
       "14           -2          +                 T           23     14\n",
       "15           -3          +                 T           26     15\n",
       "16           -1          +                 T           12     16\n",
       "17           -3          +                 T           11     17\n",
       "18           -1          +                 T           10     18\n",
       "19           -3          +                 T           12     19\n",
       "20           -2          +                 T           29     20\n",
       "21           -3          +                 T           10     21\n",
       "22           -1          +                 T            5     22\n",
       "23           -2          +                 T           12     23\n",
       "24           -1          +                 T            8     24\n",
       "25           -4          +                 T           19     25\n",
       "26            0          +                 T            7     26\n",
       "27           -2          +                 T           16     27\n",
       "28           -3          +                 T           12     28\n",
       "29           -4          +                 T           11     29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning = pd.DataFrame({'Trial': np.array(range(30)),\n",
    "                         'Reach Destination': np.array(list('T' * 30)),\n",
    "                         'Steps Taken': np.array([11, 19, 11, 9, 6, 11, 19, 12, 13, 18,\n",
    "                                                  16, 4, 6, 14, 23, 26, 12, 11, 10, 12, \n",
    "                                                  29, 10, 5, 12, 8, 19, 7, 16, 12, 11]),\n",
    "                         'Net Reward': np.array(list('+' * 30)),\n",
    "                         'Net Penalty': np.array([-2, -3, -2, -2, -1, -2, -1, -2, -2, -4, \n",
    "                                                  -2, 0, -2, -1, -2, -3, -1, -3, -1, -3, \n",
    "                                                  -2, -3, -1, -2, -1, -4, 0, -2, -3, -4])\n",
    "                         })\n",
    "print 'Steps and Net Penalty for 30 trials:'\n",
    "display(learning.drop('Trial', axis=1).describe())\n",
    "print '30 Trials:'\n",
    "display(learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
